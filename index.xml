<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ilan Reinstein</title>
    <link>https://ilanreinstein.github.io/</link>
      <atom:link href="https://ilanreinstein.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Ilan Reinstein</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 27 Aug 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ilanreinstein.github.io/media/icon_hub1d11bc70e03781f784a7270814f1676_20092_512x512_fill_lanczos_center_3.png</url>
      <title>Ilan Reinstein</title>
      <link>https://ilanreinstein.github.io/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>https://ilanreinstein.github.io/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://ilanreinstein.github.io/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>https://ilanreinstein.github.io/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://ilanreinstein.github.io/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Titanic MLOps</title>
      <link>https://ilanreinstein.github.io/project/titanic-mlops/</link>
      <pubDate>Tue, 27 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/project/titanic-mlops/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In a previous post, I told you pretty much all my trajectory in the world of data science. For the next series of entries, I&amp;rsquo;d like to stop complaining and rambling and actually do get some work done to share with you and others.&lt;/p&gt;
&lt;p&gt;One of the hardest things to move onto an engineering role is having the hands-on, practical experience and exposure to the concepts and workflows that are so natural or common to CS and Software folks. As much I try to come up with side additions to my projects at work, delivering results is a priority so there is little room to go deep on certain concepts, so I am at a constant false start on my learning. Luckily, I have established a rich list of people on LinkedIn whose content is very spot on and actually motivational.&lt;/p&gt;
&lt;p&gt;This project started as a take-home test. I was contacted and decided to give it a shot to see where I am. You guessed right, total failure. However, the right failure at the right time. After realizing how far I was able to advance, I decided to build upon my submission and use what I see daily from experts on LinkedIn to build an actual working pipeline.&lt;/p&gt;
&lt;h2 id=&#34;project-goals&#34;&gt;Project Goals&lt;/h2&gt;
&lt;p&gt;To build and expose an endpoint using a pre-trained model. The system should be able to write responses or predictions in a database and it should be packaged as a Docker container. Easy right? Well.. For someone whose experience is focused primarily on batch jobs that rely on a pristine data warehouse this was clearly a step up.&lt;/p&gt;
&lt;p&gt;Let me walk you through a couple of things I encountered along the way. If any of my takeaways, challenges, or next steps seem off, please do not hesitate to correct me or drop me a line to discuss.&lt;/p&gt;
&lt;h2 id=&#34;deliverables&#34;&gt;Deliverables&lt;/h2&gt;
&lt;p&gt;This is a simple first iteration of a personal attempt at creating a ML system from the ground. These are th components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Docker file to run the environment and fire up the API&lt;/li&gt;
&lt;li&gt;The code for feature processing and predictions&lt;/li&gt;
&lt;li&gt;A SQLite database that saves requests from the API. Only predictions are stored so far, next would be to keep a cache of &amp;ldquo;historical&amp;rdquo; features. Recall this is the Titanic competition turned into and MLOps project so more data is not available.&lt;/li&gt;
&lt;li&gt;Basic tests for the feature processing pipeline&lt;/li&gt;
&lt;li&gt;A failed attempt to draw a Cloud architecture capable of hosting such system&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The API works perfect and the database interaction is smooth. As a local Docker container I was able to obtain predictions such that ther would be no duplicate entries. A fancier and more robust way for this database interaction to happen may be nice to have.&lt;/p&gt;
&lt;h2 id=&#34;challenges&#34;&gt;Challenges&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I am mostly familiar with batch jobs that run on premise as Docker containers.&lt;/li&gt;
&lt;li&gt;The hardest part was to think about the database interaction. I found it very challenging to try and separate the components of the API along with the database. However, thinking hard about this helped me solidify my understanding of OLAP vs OLTP.&lt;/li&gt;
&lt;li&gt;The model selected for deployment made it hard to think about scale since it is a static problem from which we cannot get more data for improvement of the model, only more complex feature engineering with the embedded risk of overfitting.&lt;/li&gt;
&lt;li&gt;Lack of familiarity with API deployment and proper testing of these. Not entirely sure about the proper tests required as part of an API, but feels like a low-hanging-fruit to implement in a next iteration.&lt;/li&gt;
&lt;li&gt;Understanding the Git Workflow, other than simply creating the branches to add pieces of the application. I could improve my knowledge about collaboration with distributed teams: feature branches that depend on each other, merging strategies, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;takeaways&#34;&gt;Takeaways&lt;/h2&gt;
&lt;p&gt;I have become a firm believer that in order to learn something well, you need to face it and do it. Reading and watching tutorials will only get you so far. It is amazing how much I got out of this small project and how I can start to think about transitioning more into an MLOps role.&lt;/p&gt;
&lt;p&gt;In my humble and ignorant opinion, this has nothing to do with ML at all. It took me a few days of working in this project to realize I was doing backend engineering but maybe I&amp;rsquo;m wrong. Yes, the model quality and the data preparation steps are critical to the overall deployment performance of an inference API, but there are so many more components that are not easily taught through classic textbook examples.&lt;/p&gt;
&lt;p&gt;In addition, many of the evaluation and monitoring of a model are concepts that as far as my experience and knowledge goes, is also a recent topic of research and application. Yes, there are many tools available but as a person trying to grow and learn this only leads to vendor and option anxiety. More and more am I convinced about learning the fundamental concepts first to then go with the tool that suits the needs of the problem.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;I&amp;rsquo;d like to see how this plays out in a Cloud Environment. What are the tools for this? What is a common architecture? How would I handle the costs?
I have deployed some Docker images for R Shiny applications in the past, but this is a different animal for which the resources available are a bit overwhelming.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I am eager to integrate better tests. Not just unit tests for features but a robust data quality testing strategy, integration tests, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implement monitoring of predictions. Again, hard to do in this snapshot data problem but may be a good exercise to try out what sort of metrics I would monitor and how.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setup a CI/CD with Github actions. I have worked on GitLab for our internal projects and would like to understand how is different.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add the Features to the SQLite database. Although not entirely called for in this small, static dataset project I would be very interested in learning how to engineer Feature Stores for when you need new data daily.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find a topic of interest or another data set which could be potentially more dynamic to do retraining or model improvement via feature engineering once the infrastructure is setup. This right now seems miles away, I have so many questions on how to do this. Perhaps I should ask a Data Engineer ;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;conclussion&#34;&gt;Conclussion&lt;/h2&gt;
&lt;p&gt;This last one could be bigger than just that. I&amp;rsquo;d love to be able to choose a problem of my interest and collect some data. But I have to confess, seems a but overwhelming. It is hard to choose a topic. There are many things am interested in but none for which collecting data seems doable. Yes, I could scrape or find APIs, but I am talking about my lack for subject matter expertise on these things so it is difficult to determine common or even relevant questions that a predictive model can solve.&lt;/p&gt;
&lt;p&gt;Another thing is I don&amp;rsquo;t want to focus so much on models. There are a few things that have come to mind in terms of potential projects, eg. financial data. Currently I&amp;rsquo;m working on another personal project (more focused on Data Engineering) and there is a plenty of data with lots of possibilities. However, I know very little of Time Series and ML and Financial Models, etc. Never to late to learn but for the purpose of learning MLOps feels like a stretch.&lt;/p&gt;
&lt;p&gt;After working a few weeks on this I am happy to share this journey with you. As I get some free time on my hands I will continue to update and improve on this repo with all things I&amp;rsquo;d like to integrate. In the meantime, I am happy with the result (well, the API works). This is fun and as mentioned above, it is the best way for me to learn about something, trial and error.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Data Science Roles...</title>
      <link>https://ilanreinstein.github.io/post/on-data-science-roles/</link>
      <pubDate>Sat, 03 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/on-data-science-roles/</guid>
      <description>&lt;p&gt;Recently, I have been bashing my head against the wall as to where do I fit in the big world of data science. I consider myself a data scientist, and have been doing so for the most part of my career (7-ish years or so). But lately, ever since my title changed, my role and tasks are somewhere in a bizarre transition, or better, in an constantly-evolving void of multifaceted responsibilities which I struggle to put on a piece of paper, therefore making it hard to determine where to focus in my career development endeavors. This is in no way a rant or a complain, I simply thought it was a good moment to express my opinions of the current inventory of roles after a few years in the field.&lt;/p&gt;
&lt;p&gt;In a previous post of this blog, I wrote about how I moved from a physics degree to data science in higher education. I started off as an Associate Research Scientist: a fancy title that helped me put my name and see my contributions on multiple peer-reviewed papers, something I am very proud of. A few years later, I got my promotion and a title change to something that was odd to me at first, but with time it has started to stick with me, the infamous Data Science Engineer role.&lt;/p&gt;
&lt;p&gt;What is a Data Science Engineer?&lt;/p&gt;
&lt;p&gt;I have been asked about this in multiple conversations with people in the data space, and I always end up feeling like I could have explained it a bit better.&lt;/p&gt;
&lt;p&gt;I have been trying to put together a clear and concise definition of this role as it is not a common role you see on job boards of companies or in social networks like LinkedIn. It is why in this entry I&amp;rsquo;d like to provide a bit more insight into the profile of a Data Science Engineer and share my experience to also shed a light to anyone interested. You can read this as a blatant self-marketing/promoting piece of writing, nonetheless, I do think it is important to help job seekers &lt;em&gt;and&lt;/em&gt; companies alike understand that people like me exist and that there are no clear pathways in this &amp;ldquo;sexiest job of the 21st century BS&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;What can a Data Science Engineer do?&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll hate this answer but, pretty much anything. In my particular case, coming from a physics background I think the biggest asset has been troubleshooting, researching, and trial and error. Stats were not something that came natural to me and I had to work longer hours to try and get the concepts in my head. To the day, I still need to review basic things to understand what is going on. From a software perspective, I never really learned Computer Science basics like Data Structures and Algorithms, Architecture, none of that. However I did pick up basic (really basic) concepts pretty quickly once I started to get exposed to them, and of course, I was hooked.&lt;/p&gt;
&lt;p&gt;Are you a data scientist, data analyst, Data Engineer, or a Machine Learning Engineer?&lt;/p&gt;
&lt;p&gt;Neither and all of them. On a daily basis, I can go from crafting some interesting visuals for a paper, poster, or dashboard. The next day I am monitoring our ML pipelines and fixing the features store or codebase in case there are errors on the batch run from the night before. Some afternoons I see myself opening a stats book trying to remember how to interpret a logistic regression, or how to perform propensity score matching for a specific ad-hoc request from a stakeholder. In my free time, I troubleshoot and develop R Shiny applications as a freelancer, and I do everything from making a button work to putting the app on AWS for publication and sharing.&lt;/p&gt;
&lt;p&gt;Now here&amp;rsquo;s the problem. A data scientist by paper is focused primarily on building cool models, training algorithms in a Jupyter notebook, or reading a recent paper on some new fancy neural network architecture, I am not that person, but have been time to time. A data analyst crafts dashboards and know metrics well enough to build engaging reports after arduous data transformation work done in SQL (mostly). A Machine Learning Engineer may come more frequently from the Software Development space, with a broader knowledge on architecture, infrastructure, and super focused on more than classic statistical learning to include deep learning concepts. Finally, a data engineer focuses on building data pipelines, data models, and allocating resources usually on the cloud. This kind of profile is the one you&amp;rsquo;d hired 10 years ago for &amp;ldquo;Big Data&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;So now, back to our original question: Who am I? Why am I here? I have been exposed to many of the above &amp;ldquo;job responsibilities&amp;rdquo; to a certain degree. My role has varied by project, by business need, and by employer. I would probably attribute this to the fact that I started in data when there was still no clear definition of roles. This I take as both an advantage and a liability. On the brighter side, I have developed a set of skills that allow me to refer to myself as a Swiss Army knife of data. I can talk to different people within my organization and understand the technical jargon, which then allows me to translate easily to non-technical stakeholders and other teams. The down side, I haven&amp;rsquo;t fully developed a single path so I can continue growing with the proper focus, nor have I been capable of promoting my contributions other than say&lt;/p&gt;
&lt;p&gt;At first, as many junior data scientists, I was obsessed with advanced mathematics and their application to real-world problems. I have been lucky enough to work on a variety of projects involving complex concepts from psychometric theory and advanced statistics; the math has been there by my side and I have witnessed my impact on tangible problems. However, as time went by, I started to feel like many of my contributions were only limited to literature and academic discussions. I was slow at delivering value and outcomes because I was highly insecure about the rigor or sophistication of my work. It was at that point when I decided to focus on building stuff however imperfect, incomplete, buggy or raw it may be I just needed to put things out there.&lt;/p&gt;
&lt;p&gt;After a few months of prototyping multiple R Shiny apps and integrating cleaner code in my existing pipelines I decided to focus on moving away from the classic Data Scientist role onto a more engineering-heavy position. Many of the skills required to succeed as a ML or Data engineer come from having solid CS foundations, something a Physics degree or a data science position rarely will prepare you for. So, was this a smart move? Maybe not, as I knew I&amp;rsquo;d be climbing a steep learning curve. To be fair, my journey to become a data scientist was not short of challenges and rabbit holes, but at least the research and stats required to thrive was more &amp;ldquo;familiar&amp;rdquo; coming from physics.&lt;/p&gt;
&lt;p&gt;To be continued &amp;hellip;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Uber Data Modeling Project</title>
      <link>https://ilanreinstein.github.io/project/uber-data-modeling-project/</link>
      <pubDate>Fri, 22 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/project/uber-data-modeling-project/</guid>
      <description>&lt;p&gt;This is another project that I recently added to my learning portfolio. Thanks to Darshil Parmar&amp;rsquo;s video for the inspiration and the skeleton to get this project up and running. For anyone interested in seeing Data Engineering projects in action, please follow Darshil for more content.&lt;/p&gt;
&lt;h2 id=&#34;what-the-project-is-about&#34;&gt;What the project is about?&lt;/h2&gt;
&lt;p&gt;The project consists in using a data sample of Uber rides to create a very simple star schema to do analytics on. Darshil breaks down each of the tasks very well so it is pretty easy to follow. In addition to showing how to build each of the data model&amp;rsquo;s components, he goes on to show how to setup a basic infrastructure on Google Cloud. For orchestration he uses Mage, which I had heard about but since I was first introduced to Airflow, I never dedicated much attention to it. I have to say, I really enjoyed working on it. At least for an &amp;ldquo;easy&amp;rdquo; task such as the one worked in the toy project, I got to see the potential of such tool and how nice it is to build pipelines.&lt;/p&gt;
&lt;h2 id=&#34;what-i-learned&#34;&gt;What I learned?&lt;/h2&gt;
&lt;h3 id=&#34;data-modeling&#34;&gt;Data Modeling&lt;/h3&gt;
&lt;p&gt;The data model Darshil presents is very simple yet useful as a toy example for entry-level engineers like myself. I also did some modifications to the model given the way Polars handles the joins as opposed to Pandas, and also because I tried really hard to understand each step of the way in creating the Facts and Dimensions. For example, Darshil uses a main  key in the original table which he then uses to join with all dimensions. This seemed to work in Pandas because of the keys in both tables are preserved after the join, somthing that does not happen in Polars. Therefore, I had to revisit previous bootcamp projects to understand how to perform the final join that produces the Fact Table.&lt;/p&gt;
&lt;p&gt;If I understood correctly, I created surrogate keys for each dimension table and then I joined the resulting fact table not on these keys, but on the data fields. E.g., for Payment Type Code Dimension, I created the &lt;code&gt;payment_type_id&lt;/code&gt; variable for each unique row, and then I combined with the Fact table using the actual &lt;code&gt;payment_type_name&lt;/code&gt;, which is the only resulting column common to both Fact and Dim in this case. Again, not sure if this is the right way, but based on the way Polars handles the joins, I was left with this approach.&lt;/p&gt;
&lt;p&gt;As a consequence, I had to eliminate Location Dimensions (Lat and Long) since I would have been joining on floats. These are the main differences with what Darshil presented. I was a bit confused for a moment, but I relied on previous projects to make some progress in the project.&lt;/p&gt;
&lt;h3 id=&#34;tools&#34;&gt;Tools&lt;/h3&gt;
&lt;p&gt;I got to interact with a few new tools which I had never used before like Mage. It was pretty straightforward to deploy and setup the UI, plus it takes care of adding some simple tests to your code, which is nice and instructional.&lt;/p&gt;
&lt;p&gt;I decided to add a twist to the whole project and take Polars for a test drive. This is a newer data manipulation package in Python which has been gaining popularity and traction among my LinkedIn connections, that is why I decided to try it out. It has very similar feel to PySpark, something I really enjoyed over the few hours I spent building the ETL. I can see why people are moving away from Pandas and going to Polars, it is way faster. I did not do any proper benchmark with big size data or any comparison in performance but it is cool to see a library performing that well.&lt;/p&gt;
&lt;p&gt;I was already familiar with GCP, but as everything in life, repetition and practice are key. Seeing another example at play and understanding what each component means was a great learning experience.&lt;/p&gt;
&lt;h2 id=&#34;next-up&#34;&gt;Next up&lt;/h2&gt;
&lt;p&gt;Getting these foundations for more complex projects is highly rewarding. It is only up to now that I found some bandwidth to sit down and try to be consistent with my journey to become a better data engineer.&lt;/p&gt;
&lt;p&gt;I like taking baby steps in the learning process, I find that doing this early on compounds quicker to larger projects and experience.&lt;/p&gt;
&lt;p&gt;I will now move this exact same pipeline to AWS, and instead of Mage I will revisit Airflow.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My Journey in Data Science...</title>
      <link>https://ilanreinstein.github.io/post/my-journey-in-data-science/</link>
      <pubDate>Wed, 02 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/my-journey-in-data-science/</guid>
      <description>&lt;p&gt;Over the past few months, I have given multiple talks and participated in forums discussing my professional trajectory and my experience as a data scientist. In this post I will try to compile my path and give a few tips into how I think one may break into data science and analytics. This is not a novel guide, nor a comprehensive path to break into data science, but I think I&amp;rsquo;ve been exposed to enough to share my story.&lt;/p&gt;
&lt;h3 id=&#34;from-physics-to-data-science&#34;&gt;From physics to Data Science&lt;/h3&gt;
&lt;p&gt;When I started my undergraduate degree in physics, I knew I always wanted to do hands-on problem solving. I was undecided on which branch of engineering I should choose to fulfill my career expectations. I thought physics would give enough technical abilities and a broad exposure to science and math to eventually drift towards a more clear path into problem solving in the real world. I was surprised and wrong with how things turned out..&lt;/p&gt;
&lt;p&gt;During my third and last year of college, I was already fantasizing going into grad school to pursue a PhD in some wacky quantum-focused specialty and problem. This process led me to a lot of frustration: exam preparations, applications, finding schools and potential advisors, you name it. I started to get the feeling this pathway was not very natural to my abilities and my aspirations, I felt like forcing me to do something I was not and that brought me a lot of pain as I felt increasingly under pressure.&lt;/p&gt;
&lt;p&gt;Luckily, after a few rejections I stopped to rethink my decisions, and I thought that maybe finding a job would be a more fulfilling approach to start growing and learning new skills. I started contacting my professors, applying to jobs, and connecting with people. To my surprise, just after a few weeks after graduating, I already had multiple interviews in different sectors. This process slowly but surely presented me with opportunities and potential paths to follow in my career as a problem solver. Over the multiple interviews, I heard words like Big Data, Data Science, Machine Learning, etc. I was thrilled. I thought this was an interesting opening worth diving into and it was then in 2014 when I managed to &amp;lsquo;break into data science&amp;rsquo;.&lt;/p&gt;
&lt;h3 id=&#34;early-experiences&#34;&gt;Early experiences&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>NoteSense: Automated Assessment of Clinical Documentation</title>
      <link>https://ilanreinstein.github.io/publication/notesense-clinical-documentation/</link>
      <pubDate>Wed, 02 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/publication/notesense-clinical-documentation/</guid>
      <description>&lt;p&gt;Residents receive infrequent feedback on their clinical reasoning (CR) documentation. While machine learning (ML) and natural language processing (NLP) have been used to assess CR documentation in standardized cases, no studies have described similar use in the clinical environment.&lt;/p&gt;
&lt;p&gt;The authors developed and validated using Kane’s framework a ML model for automated assessment of CR documentation quality in residents’ admission notes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resident Retriever</title>
      <link>https://ilanreinstein.github.io/publication/resident-retriever/</link>
      <pubDate>Wed, 08 Sep 2021 07:59:01 -0500</pubDate>
      <guid>https://ilanreinstein.github.io/publication/resident-retriever/</guid>
      <description>&lt;p&gt;Residency programs face overwhelming numbers of residency applications, limiting holistic review. Artificial intelligence techniques have been proposed to address this challenge but have not been created. Here, a multidisciplinary team sought to develop and validate a machine learning (ML)-based decision support tool (DST) for residency applicant screening and review.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Curves and Multilevel Models</title>
      <link>https://ilanreinstein.github.io/publication/learning-curves-multilevel-models/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/publication/learning-curves-multilevel-models/</guid>
      <description>&lt;p&gt;This is one of the projects I am most proud of. It was a tremendously hard journey, with lots of obstacles, both technical and conceptual, which lead to a constant reformulation of our initial problem. Despite all the difficulties, we managed to build a relatively simple model which is to be tested on further studies and prototypes about learning curves. This is the project that got me started with Hierarchical Models and Bayesian Statistics. Even though we did not develop a full Bayesian model for this occasion, I was constantly learning new things about regression and multilevel models, which naturally takes you into the Bayesian world.&lt;/p&gt;
&lt;p&gt;I had the privilege to collaborate with experts in the field like Martin Pusic, Jennifer Hill, David Cook, and Matthew Lineberry, among others.&lt;/p&gt;
&lt;p&gt;If you are interested in education, adaptive learning algorithms and the potential applications of multilevel models in this type of setting, then I&amp;rsquo;m sure this paper will be quite enjoyable.&lt;/p&gt;
&lt;p&gt;Please do not hesitate to reach out with an questions you may have about this, I&amp;rsquo;ll be happy to discuss more.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NYU&#39;s COVID-19 Response</title>
      <link>https://ilanreinstein.github.io/publication/nyu-covid-19-response/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/publication/nyu-covid-19-response/</guid>
      <description>&lt;p&gt;As one of many of NYU Langone&amp;rsquo;s data scientists, I got to collaborate with the wonderful team from the Predictive Analytics Unit from NYU&amp;rsquo;s Medical Center to develop a model capable of predicting which patients will have favorable outcomes after being hospitalized. These were intense weeks not only at NYU and I am proud of being able to contribute to this project and help our physicians during these challenging times.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resources to Learn Bayesian Stats</title>
      <link>https://ilanreinstein.github.io/post/bayesian_resources/resources-to-learn-bayesian-stats/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/bayesian_resources/resources-to-learn-bayesian-stats/</guid>
      <description>&lt;p&gt;In this post, I summarize a series of resources to get started with Bayesian Statistics. I compiled these references myself based on my own experience and opinion as to what a good introduction and next steps are in this process. This is not an academic curriculum or anything tremendously rigorous, but it is a comprehensive list that will surely get you embarked on the journey to revisiting/starting your statistics. Many of the references below were recommended to me in several workshops I&amp;rsquo;ve attended and I wanted to share with those like me that want to be better at statistics and Machine Learning (ML).&lt;/p&gt;
&lt;p&gt;The first resource I can think of out there for beginners interested in Bayesian statistics and modeling is Richard McElreath’s &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Statistical Rethinking&lt;/a&gt;. Here you’ll learn everything from applying Bayes’ rule in simple problems to complex multilevel/hierarchical models. Since this is not only a book but also a full course, you should definitely follow along your reading with the &lt;a href=&#34;https://www.youtube.com/playlist?list=PLDcUM9US4XdNM4Edgs7weiyIguLSToZRI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video lectures on YouTube&lt;/a&gt;. I would encourage you to work through the code and exercises at the end of each chapter, it is the best way to start getting hands on expertise in this topic. Another great thing is that the book’s R package &lt;a href=&#34;https://github.com/rmcelreath/rethinking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rethinking&lt;/code&gt;&lt;/a&gt; and all the example code has been translated into multiple programming languages, so you are free to choose the one of your preference to go through the reading.&lt;/p&gt;
&lt;p&gt;A powerful reference for those that feel like brushing up your stats with real-world examples, Andrew Gelman and Jennifer Hill’s &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data Analysis Using Regression and Multilevel/Hierarchical Models&lt;/a&gt; is a fantastic book for those with more interest on Applied Statistics on a social science setting. An updated version of this book is called &lt;a href=&#34;https://avehtari.github.io/ROS-Examples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Regression and Other Stories&lt;/a&gt; (Andrew Gelman, Jennifer Hill, Aki Vehtari) and it will be released later this year. If you&amp;rsquo;d like to work through another more advanced course on Bayesian Statistics, I suggest you visit &lt;a href=&#34;https://github.com/avehtari/BDA_course_Aalto&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aki Vehtari’s teaching page&lt;/a&gt;. Although more challenging than McElreath&amp;rsquo;s class it is worth checking it out. Again, the course material is available in R and Python.&lt;/p&gt;
&lt;p&gt;Now, you’ve refreshed your basic stats and gone through most of McElreath’s book, but you are also looking into ML. You may wonder, where should I go? What to do next? Challenge yourself to read Christopher Bishop’s &lt;a href=&#34;https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;. Bishop’s book presents all the well known ML concepts from regression and classification to neural networks through a concealed Bayesian lens. It is fair to say that I&amp;rsquo;ve deeply strengthen my knowledge in both ML and Bayesian statistics just by working through the first chapters. Although I highly recommend it, keep in mind this is an advanced book and it takes some time to get your head around the concepts.&lt;/p&gt;
&lt;p&gt;At the same level as Bishop’s book, you can also find a rigorous and detailed explanation of Bayesian statistics and modeling on &lt;a href=&#34;http://www.inference.org.uk/mackay/itila/book.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David MacKay’s Information Theory, Inference, and Learning Algorithms&lt;/a&gt;. I was fortunate enough to use this book in college, and it still proves to be essential whenever I want to revisit some probability concepts, Bayesian statistics and ML. The book&amp;rsquo;s webpage also provides software resources and examples for you to experiment and play around as you navigate the text.&lt;/p&gt;
&lt;p&gt;Whenever you feel comfortable enough with the basics to go deeper into the math and the theoretical concepts behind probabilistic modeling, probabilistic computation and applied Bayesian Statistics I strongly encourage you to read &lt;em&gt;all&lt;/em&gt; of &lt;a href=&#34;https://betanalpha.github.io/writing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Michael Betancourt’s case studies&lt;/a&gt; in due order. This will be challenging to grasp at first, but as you go back over the content and dedicate the time to understand these concepts, the reward is huge.&lt;/p&gt;
&lt;p&gt;It is not very often that you hear about the success stories of Bayesian methods in industry, specially nowadays against the huge amount of attention on ML and AI. For those that like podcasts to listen to stories about practitioners and people applying Bayesian statistics to their fields I strongly advise that you check out Alexandre Andorra&amp;rsquo;s podcast Learning Bayesian Statistics. Alex does an amazing job at interviewing professionals from a wide variety of fields, with incredibly diverse backgrounds and experiences, hence introducing you to the vast universe of applications of Bayesian statistics.&lt;/p&gt;
&lt;p&gt;One final thing that it is a hard requirement and a common thread between the references and resources listed above is Markov Chain Monte Carlo (MCMC). In order to fully explore probability spaces and distributions you need efficient and reliable computational methods like MCMC and its advanced variants. Today, many programming languages are capable of implementing such advanced estimation algorithm but the most popular are 1) &lt;a href=&#34;https://mc-stan.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stan&lt;/a&gt;, which is built on C++ and has multiple interfaces to R (&lt;a href=&#34;http://mc-stan.org/rstanarm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rstanarm&lt;/a&gt;, &lt;a href=&#34;https://paul-buerkner.github.io/brms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;brms&lt;/a&gt;), Python (&lt;a href=&#34;https://pystan.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyStan&lt;/a&gt;), Julia and others; and 2) &lt;a href=&#34;https://docs.pymc.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyMC3&lt;/a&gt;. If you are interested in learning the basics you may visit their webpages to see examples with code.&lt;/p&gt;
&lt;p&gt;Some personal remarks on my own journey through Bayesian Statistics. This topic is not easy, you should invest some time to see some progress. The references above are a great starting point and I’ve noticed an important step forward in my learning path by trying to apply Bayesian methods to my own work. For me, its fundamentals are more intuitive and transparent, and overall simpler to grasp (at least conceptually), but considerably harder to apply.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kaggle Survey 2019 Analysis</title>
      <link>https://ilanreinstein.github.io/project/kaggle-survey-2019/kaggle-survey-2019-latin-america-ml-community/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/project/kaggle-survey-2019/kaggle-survey-2019-latin-america-ml-community/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Content on Machine Learning</title>
      <link>https://ilanreinstein.github.io/post/data-turbulence/content-machine-learning/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/data-turbulence/content-machine-learning/</guid>
      <description>&lt;p&gt;As part of my journey in Statistics and Machine Learning, I was fortunate enough to write original content about popular libraries, algorithms and software packages used in this line of work. This content was all developed during the time I worked with KDnuggets, a site that is widely recognized for its contributions on content about recent advances in the field of Big Data and Predictive Analytics.&lt;/p&gt;
&lt;p&gt;You may visit the site and my contributions on this &lt;a href=&#34;https://www.kdnuggets.com/author/ilan-reinstein&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hope you enjoy it!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Latin America&#39;s Energy Market</title>
      <link>https://ilanreinstein.github.io/post/iadb-energy-viz/latin-america-energy-market/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/iadb-energy-viz/latin-america-energy-market/</guid>
      <description>&lt;p&gt;As part of a consultancy project I did for the Interamerican Development Bank (IADB), I worked closely with the Energy and  Oil &amp;amp; Gas division to develop a series of interactive tools that would allow them to summarize their data in a friendly way , and so that this information may be shared internally with other departments and externally with stakeholders, i.e., countries and governments.&lt;/p&gt;
&lt;p&gt;The data used for this project was provided internally by the bank, as well as gathered from different sources like BP&amp;rsquo;s Annual Energy Report, OECD data, World Bank data, and OPEC data among others.&lt;/p&gt;
&lt;p&gt;The actual product consists in a series of interactive maps developed in D3, and it is hosted inside the bank, therefore data and code may not be shared. However, an overview of the project may be observed in the following pictures.I hope you like my visualization work!&lt;/p&gt;
&lt;p&gt;Cheers!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Energy Efficiency and Intensity&lt;/strong&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ilanreinstein.github.io/media/img/eficiencia.png&#34; alt=&#34;img1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gas Consumption Aggregated and General Information&lt;/strong&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ilanreinstein.github.io/media/img/gas-consum-overall.png&#34; alt=&#34;img2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gas Consumption Diasggregated&lt;/strong&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ilanreinstein.github.io/media/img/gas-consum.png&#34; alt=&#34;img3&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gas Import and Export Data&lt;/strong&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ilanreinstein.github.io/media/img/gas-import-export.png&#34; alt=&#34;img4&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Six Degress of Data Turbulence</title>
      <link>https://ilanreinstein.github.io/post/data-turbulence/six-degress-of-data-turbulence/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/data-turbulence/six-degress-of-data-turbulence/</guid>
      <description>&lt;p&gt;Finally, I have made some time to begin adding some interesting content to this blog. I&amp;rsquo;ve been looking for a few minutes to gather some of the music I&amp;rsquo;ve heard lately, and decide which one has been the most &lt;strong&gt;resonant&lt;/strong&gt; with my daily mood. If you don&amp;rsquo;t like heavy metal, progressive music, or psychedelic rock, then maybe this site is not for you. If you do like it, then I will try to come up with great suggestions for you to listen during those times of tremendous focus. I am one of those people that needs to listen to some tunes in order to work faster and better, otherwise my routine will be dull, unexciting, and even worst, a field trip to my attention span. If sometimes you feel the same way, welcome to &lt;strong&gt;Resonance,&lt;/strong&gt; where the musical recommendations are intended to resonate with your working day, in particular, while performing Data Science related tasks like data cleaning, testing, scripting, plotting, Kaggling, etc.&lt;/p&gt;
&lt;p&gt;I also hope this blog helps you and I explore new music for Data Science. I clearly intend to hear suggestions from others and apply them to whatever working mood I feel on a given day: your thoughts and ideas are welcome here. So, without further ado, here is the first entry of this blog. Please enjoy, rock on, and keep working.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Today, I&amp;rsquo;ve been collecting information about Data Science and Analytics graduate programs around Europe. It has been a very mechanic, almost automatic activity, so I thought something structured, powerful, and continuous was necessary. That is why I tuned into Dream Theater, specifically, Six Degrees of Inner Turbulence. This album is from the early 2000&amp;rsquo;s and it is divided into two. I&amp;rsquo;ve had this album on my library for years now, but it was only until about a couple of weeks that I listened to it carefully while cruising the web and writing some code. I was blown away by the amount of work I managed to complete for the duration of the record.&lt;/p&gt;
&lt;p&gt;I kept playing it for next days while working and I was amazed by how much energy the album can transmit. The highly structured rhythm patterns and complex compositions are just amazing, as well as the diversity and variety of the songs, just enough variability to keep you interested and focused at the same time. One particular aspect of the album, which I think contributes enormously to my productivity, is the longevity and continuity of every song: a not uncommon feature in the band&amp;rsquo;s writing and playing style. The fact that you don&amp;rsquo;t notice when a song ends and the other begins is a key factor to stay focused as you hardly keep track of how much time has passed. That feeling, I believe is key when finding the right piece to sit down and get things done, an overwhelming sense of non-advancing, infinite time.&lt;/p&gt;
&lt;p&gt;Listening to Portnoy&amp;rsquo;s double kick for hours is the best medicine for restlessness and constant distractions. If you manage to keep up with with his pace, you will most definitely maintain full concentration for long period of time, even at late-night hours. When is not the drums, someone else is going to be hitting those 16th notes at high speeds, and that for me is uplifting and motivating.&lt;/p&gt;
&lt;p&gt;As you begin the album, you are greeted by The Glass Prison, an absolute 14-minute masterpiece, enough to get your to-do lists done at a nice rhythm. Then comes Blind Faith, usually this is the one that I need to listen to with full attention, I just enjoy that song too much. You will continue through this first part with great stamina and focus, and then&amp;hellip; Overture. A majestic instrumental piece which opens up the gates to what I think is the more conceptual part of the album, and from there on, the album has already absorbed you into its full depth. An interesting fact, if you listen to Dream Theater&amp;rsquo;s albums carefully, and in alphabetical order, for example, Scenes From a Memory -&amp;gt; Six Degrees, you will see that they are perfectly connected so you could listen to them for an entire day! However, we will not dive into that today so let&amp;rsquo;s return to our idea.&lt;/p&gt;
&lt;p&gt;By the time I&amp;rsquo;ve finished the album, I have already crossed out more than half of my daily tasks and it&amp;rsquo;s not even lunch time. This album not just gives me push and stamina, but it is also loud and powerful enough to keep me focused and calm. On stressful days, listening to something heavy is always good, you don&amp;rsquo;t hear the noise of unnecessary worries and problems in your head, you manage to just keep moving and finish everything properly without being so restless. Needless to say, it&amp;rsquo;s Dream Theater we are talking about, so I had to stop every now and then to grasp and enjoy the epic guitar solos and the long, loud, and melancholic finales.&lt;/p&gt;
&lt;p&gt;I hope you listen and enjoy this incredibly epic, conceptual, fast-paced album. In a future post, I will write more about Dream Theater as it is my go-to band during working hours. They have tons of material, highly suited to do data science, so I will be circling back to them.&lt;/p&gt;
&lt;p&gt;Rock n&#39; roll&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My first data stories...</title>
      <link>https://ilanreinstein.github.io/post/data-stories/my-first-data-stories/</link>
      <pubDate>Tue, 01 Apr 2014 00:00:00 +0000</pubDate>
      <guid>https://ilanreinstein.github.io/post/data-stories/my-first-data-stories/</guid>
      <description>&lt;p&gt;This post is simply to display and promote some of my early projects in analytics and data visualization. The topics are diverse, ranging from sports to energy economics. These are simply some exploratory and visual analyses I performed in 2014 when trying to promote our product. The purpose of these posts was to educate businesses on the potential of data-driven decisions as well as showcase and expose our data products and solutions.&lt;/p&gt;
&lt;p&gt;I am very fond of these small projects as it was my first experience using R and performing data analytics and visualization, thus encouraging me to pursue a career in data science. I hope you enjoy the read and the insight. I will try to produce newer posts in the near future.&lt;/p&gt;
&lt;p&gt;Follow this link to see the full &lt;a href=&#34;http://rpubs.com/ireinstein&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Portfolio&lt;/a&gt; with both the code and the data story.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
